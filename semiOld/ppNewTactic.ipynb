{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.svm import SVC\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "downtime_data = pd.read_excel('../Raw Data/Equipment downtime data (202308).xlsx')\n",
    "hierarchy_data = pd.read_excel('../Raw Data/Operation level of equipment.xlsx')\n",
    "downtimeNew = pd.read_excel('../Raw Data/Equipment downtime data (202310).xlsx')\n",
    "downtime_data.to_csv('../Raw Data/Equipment downtime data (202308).csv', index=False)\n",
    "hierarchy_data.to_csv('../Raw Data/Operation level of equipment.csv', index=False)\n",
    "downtimeNew.to_csv('../Raw Data/Equipment downtime data (202310).csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reformatting date and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "downtime_data['FaultDate'] = pd.to_datetime(downtime_data['FaultDate'], errors='coerce').dt.date\n",
    "downtimeNew['FaultDate'] = pd.to_datetime(downtimeNew['FaultDate'], errors='coerce').dt.date\n",
    "downtime_data['FaultTime'] = downtime_data['FaultTime'].apply(lambda x: x.strftime('%H:%M:%S') if len(str(x)) > 8 else x)\n",
    "downtimeNew['FaultTime'] = downtimeNew['FaultTime'].apply(lambda x: x.strftime('%H:%M:%S') if len(str(x)) > 8 else x)\n",
    "downtimeNew = downtimeNew.dropna(subset=['FaultDate', 'FaultTime'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping data that is not needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_data = downtime_data.iloc[:, :14]\n",
    "pattern_new = downtimeNew.iloc[:, :14]\n",
    "pattern_data = pattern_data.drop(['ID', 'DutyOfficer', 'Manager email address'], axis=1)\n",
    "pattern_new = pattern_new.drop(['ID', 'DutyOfficer', 'Manager email address'], axis=1)\n",
    "pattern_data['FaultDateTime'] = pd.to_datetime(pattern_data['FaultDate'].astype(str) + ' ' + pattern_data['FaultTime'].astype(str))\n",
    "pattern_new['FaultDateTime'] = pd.to_datetime(pattern_new['FaultDate'].astype(str) + ' ' + pattern_new['FaultTime'].astype(str))\n",
    "dt2010 = pd.to_datetime('2010-01-01 00:00:00')\n",
    "dtnew = pd.to_datetime('2023-08-04 06:00:00')\n",
    "pattern_data.drop(['FaultDate', 'FaultTime'], axis=1, inplace=True)\n",
    "pattern_new.drop(['FaultDate', 'FaultTime'], axis=1, inplace=True)\n",
    "pattern_data.sort_values(by=['FaultDateTime'], inplace=True)\n",
    "pattern_new.sort_values(by=['FaultDateTime'], inplace=True)\n",
    "pattern_data = pattern_data[pattern_data['FaultDateTime'] >= dt2010]\n",
    "pattern_new = pattern_new[pattern_new['FaultDateTime'] >= dtnew]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_data = pattern_data.drop(['LogEntry', 'DutyOfficer comments', 'Managerscomments', 'FaultRepair', 'FaultDescription', 'Group', 'Downtime', 'User Run'], axis=1)\n",
    "pattern_new = pattern_new.drop(['LogEntry', 'DutyOfficer comments', 'Managerscomments', 'FaultRepair', 'FaultDescription', 'Group', 'Downtime', 'User Run'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing for labeling and encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nl/8bkjfnbd2k53t1p3_gjy6k9h0000gn/T/ipykernel_54837/772714026.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  pattern_data['Equipment'] = pattern_data['Equipment'].str.replace('[^\\w\\s]', '')\n"
     ]
    }
   ],
   "source": [
    "pattern_data['Equipment'] = pattern_data['Equipment'].str.lower()\n",
    "pattern_data['Equipment'] = pattern_data['Equipment'].str.replace('[^\\w\\s]', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nl/8bkjfnbd2k53t1p3_gjy6k9h0000gn/T/ipykernel_54837/656363772.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  pattern_new['Equipment'] = pattern_new['Equipment'].str.replace('[^\\w\\s]', '')\n"
     ]
    }
   ],
   "source": [
    "pattern_new['Equipment'] = pattern_new['Equipment'].str.lower()\n",
    "pattern_new['Equipment'] = pattern_new['Equipment'].str.replace('[^\\w\\s]', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the data frame for backwards tracking from failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfprec = pd.DataFrame(columns=set(pattern_data['Equipment'].tolist()))\n",
    "for label in dfprec:\n",
    "    dfprec[label] = [0]*pattern_data.shape[0]\n",
    "labels = pd.DataFrame()\n",
    "labels['Label'] = [0]*pattern_data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling out the data frame and creating labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/svetozarmiloshevski/Man/BSc. Artificial Intelligence Year 3/Dissertation Fresh/ISIS-Ion-Source-Reliability/ppNewTactic.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/svetozarmiloshevski/Man/BSc.%20Artificial%20Intelligence%20Year%203/Dissertation%20Fresh/ISIS-Ion-Source-Reliability/ppNewTactic.ipynb#X21sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mif\u001b[39;00m (cur_dt \u001b[39m-\u001b[39m inner_dt) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m twindow:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/svetozarmiloshevski/Man/BSc.%20Artificial%20Intelligence%20Year%203/Dissertation%20Fresh/ISIS-Ion-Source-Reliability/ppNewTactic.ipynb#X21sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39mif\u001b[39;00m j \u001b[39m!=\u001b[39m i:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/svetozarmiloshevski/Man/BSc.%20Artificial%20Intelligence%20Year%203/Dissertation%20Fresh/ISIS-Ion-Source-Reliability/ppNewTactic.ipynb#X21sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m         dfprec[inner_eq][i] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/svetozarmiloshevski/Man/BSc.%20Artificial%20Intelligence%20Year%203/Dissertation%20Fresh/ISIS-Ion-Source-Reliability/ppNewTactic.ipynb#X21sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/svetozarmiloshevski/Man/BSc.%20Artificial%20Intelligence%20Year%203/Dissertation%20Fresh/ISIS-Ion-Source-Reliability/ppNewTactic.ipynb#X21sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/series.py:1075\u001b[0m, in \u001b[0;36mSeries.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   1073\u001b[0m check_deprecated_indexers(key)\n\u001b[1;32m   1074\u001b[0m key \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mapply_if_callable(key, \u001b[39mself\u001b[39m)\n\u001b[0;32m-> 1075\u001b[0m cacher_needs_updating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_is_chained_assignment_possible()\n\u001b[1;32m   1077\u001b[0m \u001b[39mif\u001b[39;00m key \u001b[39mis\u001b[39;00m \u001b[39mEllipsis\u001b[39m:\n\u001b[1;32m   1078\u001b[0m     key \u001b[39m=\u001b[39m \u001b[39mslice\u001b[39m(\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/series.py:1255\u001b[0m, in \u001b[0;36mSeries._check_is_chained_assignment_possible\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_view \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_cached:\n\u001b[1;32m   1254\u001b[0m     ref \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_cacher()\n\u001b[0;32m-> 1255\u001b[0m     \u001b[39mif\u001b[39;00m ref \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m ref\u001b[39m.\u001b[39;49m_is_mixed_type:\n\u001b[1;32m   1256\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_setitem_copy(t\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mreferent\u001b[39m\u001b[39m\"\u001b[39m, force\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   1257\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/generic.py:5688\u001b[0m, in \u001b[0;36mNDFrame._is_mixed_type\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5683\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mgr\u001b[39m.\u001b[39many_extension_types:\n\u001b[1;32m   5684\u001b[0m     \u001b[39m# Even if they have the same dtype, we can't consolidate them,\u001b[39;00m\n\u001b[1;32m   5685\u001b[0m     \u001b[39m#  so we pretend this is \"mixed'\"\u001b[39;00m\n\u001b[1;32m   5686\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m-> 5688\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtypes\u001b[39m.\u001b[39mnunique() \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/generic.py:5755\u001b[0m, in \u001b[0;36mNDFrame.dtypes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5728\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   5729\u001b[0m \u001b[39mReturn the dtypes in the DataFrame.\u001b[39;00m\n\u001b[1;32m   5730\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5752\u001b[0m \u001b[39mdtype: object\u001b[39;00m\n\u001b[1;32m   5753\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   5754\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mgr\u001b[39m.\u001b[39mget_dtypes()\n\u001b[0;32m-> 5755\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_constructor_sliced(data, index\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_info_axis, dtype\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mobject_)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/series.py:367\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    365\u001b[0m     name \u001b[39m=\u001b[39m ibase\u001b[39m.\u001b[39mmaybe_extract_name(name, data, \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m))\n\u001b[0;32m--> 367\u001b[0m     \u001b[39mif\u001b[39;00m is_empty_data(data) \u001b[39mand\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    368\u001b[0m         \u001b[39m# gh-17261\u001b[39;00m\n\u001b[1;32m    369\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    370\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe default dtype for empty Series will be \u001b[39m\u001b[39m'\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m'\u001b[39m\u001b[39m instead \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    371\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mof \u001b[39m\u001b[39m'\u001b[39m\u001b[39mfloat64\u001b[39m\u001b[39m'\u001b[39m\u001b[39m in a future version. Specify a dtype explicitly \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    374\u001b[0m             stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    375\u001b[0m         )\n\u001b[1;32m    376\u001b[0m         \u001b[39m# uncomment the line below when removing the FutureWarning\u001b[39;00m\n\u001b[1;32m    377\u001b[0m         \u001b[39m# dtype = np.dtype(object)\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/construction.py:817\u001b[0m, in \u001b[0;36mis_empty_data\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    804\u001b[0m \u001b[39mUtility to check if a Series is instantiated with empty data,\u001b[39;00m\n\u001b[1;32m    805\u001b[0m \u001b[39mwhich does not contain dtype information.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[39mbool\u001b[39;00m\n\u001b[1;32m    815\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    816\u001b[0m is_none \u001b[39m=\u001b[39m data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 817\u001b[0m is_list_like_without_dtype \u001b[39m=\u001b[39m is_list_like(data) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39;49m(data, \u001b[39m\"\u001b[39;49m\u001b[39mdtype\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    818\u001b[0m is_simple_empty \u001b[39m=\u001b[39m is_list_like_without_dtype \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m data\n\u001b[1;32m    819\u001b[0m \u001b[39mreturn\u001b[39;00m is_none \u001b[39mor\u001b[39;00m is_simple_empty\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "twindow = pd.Timedelta(days=5)\n",
    "for i in range(pattern_data.shape[0]):\n",
    "    cur_eq = pattern_data.iloc[i]['Equipment']\n",
    "    cur_dt = pattern_data.iloc[i]['FaultDateTime']\n",
    "    if cur_eq == 'ion source':\n",
    "        labels.iloc[i]['Label'] = 1\n",
    "        dfprec[cur_eq][i] -= 1\n",
    "    for j in range(i, -1, -1):\n",
    "        inner_eq = pattern_data.iloc[j]['Equipment']\n",
    "        inner_dt = pattern_data.iloc[j]['FaultDateTime']\n",
    "        if (cur_dt - inner_dt) <= twindow:\n",
    "            if j != i:\n",
    "                dfprec[inner_eq][i] += 1\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_x, testing_x, training_y, testing_y = train_test_split(dfprec, labels, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9674713584288053, Precision: 0.7883211678832117, Recall: 0.453781512605042, F1-Score: 0.576\n",
      "Confusion Matrix: \n",
      " [[4621   29]\n",
      " [ 130  108]]\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    ")\n",
    "training_x.fillna(-1, inplace=True)\n",
    "testing_x.fillna(-1, inplace=True)\n",
    "\n",
    "rf.fit(training_x, training_y['Label'])\n",
    "rf_pred = rf.predict(testing_x)\n",
    "\n",
    "accuracy = accuracy_score(testing_y, rf_pred)\n",
    "precision = precision_score(testing_y, rf_pred, zero_division=1)\n",
    "recall = recall_score(testing_y, rf_pred, zero_division=1)\n",
    "f1 = f1_score(testing_y, rf_pred, zero_division=1)\n",
    "conf = confusion_matrix(testing_y, rf_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1-Score: {f1}\")\n",
    "print(f\"Confusion Matrix: \\n {conf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9615384615384616, Precision: 0.9166666666666666, Recall: 0.23109243697478993, F1-Score: 0.3691275167785235\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(training_x, label=training_y)\n",
    "\n",
    "dtest = xgb.DMatrix(testing_x)\n",
    "\n",
    "num_round = 100\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'max_depth': 3,\n",
    "    'eta': 0.1,\n",
    "    'eval_metric': 'logloss',\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'scale_pos_weight': len(training_y[training_y == 0]) / len(training_y[training_y == 1])\n",
    "}\n",
    "\n",
    "model_labels = xgb.train(params, dtrain, num_round)\n",
    "\n",
    "model_pred = model_labels.predict(dtest)\n",
    "\n",
    "model_pred = [int(round(value)) for value in model_pred]\n",
    "\n",
    "accuracy = accuracy_score(testing_y, model_pred)\n",
    "precision = precision_score(testing_y, model_pred)\n",
    "recall = recall_score(testing_y, model_pred)\n",
    "f1 = f1_score(testing_y, model_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1-Score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at n number of failures and predict if fail will happen in X days (3 for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set1 = set(pattern_data['Equipment'].tolist())\n",
    "set2 = set(pattern_new['Equipment'].tolist())\n",
    "combined = set1.union(set2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfprec1 = pd.DataFrame(columns=combined)\n",
    "for label in dfprec1:\n",
    "    dfprec1[label] = [0]*pattern_data.shape[0]\n",
    "labels1 = pd.DataFrame()\n",
    "labels1['Label'] = [0]*pattern_data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For verification purposes for latest user run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfprecnew = pd.DataFrame(columns=combined)\n",
    "for label in dfprecnew:\n",
    "    dfprecnew[label] = [0]*pattern_new.shape[0]\n",
    "labelsnew = pd.DataFrame()\n",
    "labelsnew['Label'] = [0]*pattern_new.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data frames and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twindow = pd.Timedelta(days=3)\n",
    "for i in range(pattern_data.shape[0]):\n",
    "    temp = 0\n",
    "    for j in range(i, i+40):\n",
    "        if j>=pattern_data.shape[0]:\n",
    "            break\n",
    "        inner_eq = pattern_data.iloc[j]['Equipment']\n",
    "        dfprec1[inner_eq][i] += 1\n",
    "        temp = j\n",
    "    cur_dt = pattern_data.iloc[temp]['FaultDateTime']\n",
    "    for j in range(temp, pattern_data.shape[0]):\n",
    "        inner_eq = pattern_data.iloc[j]['Equipment']\n",
    "        inner_dt = pattern_data.iloc[j]['FaultDateTime']\n",
    "        if inner_eq == 'ion source':\n",
    "            labels1.iloc[i]['Label'] = 1\n",
    "            break\n",
    "        if (inner_dt - cur_dt) >= twindow:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twindow = pd.Timedelta(days=3)\n",
    "for i in range(pattern_new.shape[0]):\n",
    "    temp = 0\n",
    "    for j in range(i, i+40):\n",
    "        if j>=pattern_new.shape[0]:\n",
    "            break\n",
    "        inner_eq = pattern_new.iloc[j]['Equipment']\n",
    "        dfprecnew[inner_eq][i] += 1\n",
    "        temp = j\n",
    "    cur_dt = pattern_new.iloc[temp]['FaultDateTime']\n",
    "    for j in range(temp, pattern_new.shape[0]):\n",
    "        inner_eq = pattern_new.iloc[j]['Equipment']\n",
    "        inner_dt = pattern_new.iloc[j]['FaultDateTime']\n",
    "        if inner_eq == 'ion source':\n",
    "            labelsnew.iloc[i]['Label'] = 1\n",
    "            break\n",
    "        if (inner_dt - cur_dt) >= twindow:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_combined = pd.concat([pattern_data, pattern_new], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpreccomb = pd.DataFrame(columns=combined)\n",
    "for label in dfpreccomb:\n",
    "    dfpreccomb[label] = [0]*pattern_combined.shape[0]\n",
    "labelscombined = pd.DataFrame()\n",
    "labelscombined['Label'] = [0]*pattern_combined.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twindow = pd.Timedelta(days=3)\n",
    "for i in range(pattern_combined.shape[0]):\n",
    "    temp = 0\n",
    "    for j in range(i, i+40):\n",
    "        if j>=pattern_combined.shape[0]:\n",
    "            break\n",
    "        inner_eq = pattern_combined.iloc[j]['Equipment']\n",
    "        dfpreccomb[inner_eq][i] += 1\n",
    "        temp = j\n",
    "    cur_dt = pattern_combined.iloc[temp]['FaultDateTime']\n",
    "    for j in range(temp, pattern_combined.shape[0]):\n",
    "        inner_eq = pattern_combined.iloc[j]['Equipment']\n",
    "        inner_dt = pattern_combined.iloc[j]['FaultDateTime']\n",
    "        if inner_eq == 'ion source':\n",
    "            labelscombined.iloc[i]['Label'] = 1\n",
    "            break\n",
    "        if (inner_dt - cur_dt) >= twindow:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_x, testing_x, training_y, testing_y = train_test_split(dfprec1, labels1, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.978518821603928, Precision: 0.9759463722397477, Recall: 0.982532751091703, F1-Score: 0.9792284866468843\n",
      "Confusion Matrix: \n",
      " [[2308   61]\n",
      " [  44 2475]]\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    criterion='entropy',\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    bootstrap=True,\n",
    "\n",
    ")\n",
    "training_x.fillna(-1, inplace=True)\n",
    "testing_x.fillna(-1, inplace=True)\n",
    "\n",
    "rf.fit(training_x, training_y['Label'])\n",
    "rf_pred = rf.predict(testing_x)\n",
    "\n",
    "accuracy = accuracy_score(testing_y, rf_pred)\n",
    "precision = precision_score(testing_y, rf_pred, zero_division=1)\n",
    "recall = recall_score(testing_y, rf_pred, zero_division=1)\n",
    "f1 = f1_score(testing_y, rf_pred, zero_division=1)\n",
    "conf = confusion_matrix(testing_y, rf_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1-Score: {f1}\")\n",
    "print(f\"Confusion Matrix: \\n {conf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6092436974789915, Precision: 0.6420454545454546, Recall: 0.7902097902097902, F1-Score: 0.7084639498432602\n",
      "Confusion Matrix: \n",
      " [[ 64 126]\n",
      " [ 60 226]]\n"
     ]
    }
   ],
   "source": [
    "rf_prednew = rf.predict(dfprecnew)\n",
    "accuracy = accuracy_score(labelsnew, rf_prednew)\n",
    "precision = precision_score(labelsnew, rf_prednew, zero_division=1)\n",
    "recall = recall_score(labelsnew, rf_prednew, zero_division=1)\n",
    "f1 = f1_score(labelsnew, rf_prednew, zero_division=1)\n",
    "conf = confusion_matrix(labelsnew, rf_prednew)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1-Score: {f1}\")\n",
    "print(f\"Confusion Matrix: \\n {conf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7780278232405892, Precision: 0.7858851674641149, Recall: 0.7824533545057563, F1-Score: 0.7841655062661628\n",
      "Confusion Matrix: \n",
      " [[1832  537]\n",
      " [ 548 1971]]\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(training_x, label=training_y)\n",
    "\n",
    "dtest = xgb.DMatrix(testing_x)\n",
    "\n",
    "num_round = 100\n",
    "\n",
    "params = {\n",
    "    'max_depth': 3,\n",
    "    'eta': 0.1\n",
    "}\n",
    "\n",
    "model_labels = xgb.train(params, dtrain, num_round)\n",
    "\n",
    "model_pred = model_labels.predict(dtest)\n",
    "\n",
    "model_pred = [int(round(value)) for value in model_pred]\n",
    "\n",
    "accuracy = accuracy_score(testing_y, model_pred)\n",
    "precision = precision_score(testing_y, model_pred)\n",
    "recall = recall_score(testing_y, model_pred)\n",
    "f1 = f1_score(testing_y, model_pred)\n",
    "conf = confusion_matrix(testing_y, model_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1-Score: {f1}\")\n",
    "print(f\"Confusion Matrix: \\n {conf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7375204582651391, Precision: 0.7634271099744245, Recall: 0.7109964271536324, F1-Score: 0.7362795477903392\n",
      "Confusion Matrix: \n",
      " [[1814  555]\n",
      " [ 728 1791]]\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(\n",
    "    C=1,\n",
    "    kernel='rbf',\n",
    "    gamma=0.001,\n",
    "    max_iter=-1\n",
    ")\n",
    "\n",
    "svc.fit(training_x, training_y['Label'])\n",
    "svc_pred = svc.predict(testing_x)\n",
    "\n",
    "accuracy = accuracy_score(testing_y, svc_pred)\n",
    "precision = precision_score(testing_y, svc_pred)\n",
    "recall = recall_score(testing_y, svc_pred)\n",
    "f1 = f1_score(testing_y, svc_pred)\n",
    "conf = confusion_matrix(testing_y, svc_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1-Score: {f1}\")\n",
    "print(f\"Confusion Matrix: \\n {conf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5861344537815126, Precision: 0.6072289156626506, Recall: 0.8811188811188811, F1-Score: 0.7189728958630528\n",
      "Confusion Matrix: \n",
      " [[ 27 163]\n",
      " [ 34 252]]\n"
     ]
    }
   ],
   "source": [
    "svc_prednew = svc.predict(dfprecnew)\n",
    "accuracy = accuracy_score(labelsnew, svc_prednew)\n",
    "precision = precision_score(labelsnew, svc_prednew)\n",
    "recall = recall_score(labelsnew, svc_prednew)\n",
    "f1 = f1_score(labelsnew, svc_prednew)\n",
    "conf = confusion_matrix(labelsnew, svc_prednew)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1-Score: {f1}\")\n",
    "print(f\"Confusion Matrix: \\n {conf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "611/611 [==============================] - 1s 1ms/step - loss: 0.4935 - accuracy: 0.7557\n",
      "Epoch 2/10\n",
      "611/611 [==============================] - 1s 1ms/step - loss: 0.2715 - accuracy: 0.8895\n",
      "Epoch 3/10\n",
      "611/611 [==============================] - 1s 1ms/step - loss: 0.1821 - accuracy: 0.9273\n",
      "Epoch 4/10\n",
      "611/611 [==============================] - 1s 1ms/step - loss: 0.1409 - accuracy: 0.9443\n",
      "Epoch 5/10\n",
      "611/611 [==============================] - 1s 1ms/step - loss: 0.1185 - accuracy: 0.9533\n",
      "Epoch 6/10\n",
      "611/611 [==============================] - 1s 1ms/step - loss: 0.1055 - accuracy: 0.9601\n",
      "Epoch 7/10\n",
      "611/611 [==============================] - 1s 1ms/step - loss: 0.0964 - accuracy: 0.9619\n",
      "Epoch 8/10\n",
      "611/611 [==============================] - 1s 2ms/step - loss: 0.0908 - accuracy: 0.9645\n",
      "Epoch 9/10\n",
      "611/611 [==============================] - 1s 2ms/step - loss: 0.0796 - accuracy: 0.9684\n",
      "Epoch 10/10\n",
      "611/611 [==============================] - 1s 1ms/step - loss: 0.0790 - accuracy: 0.9679\n",
      "153/153 [==============================] - 0s 798us/step\n",
      "0.9722111949186185\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=1)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(512, input_dim=training_x.shape[1], activation='relu'),\n",
    "    keras.layers.Dense(256, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(training_x, training_y, epochs=10, batch_size=32)\n",
    "\n",
    "y_pred = (model.predict(testing_x) > 0.5).astype(int)\n",
    "\n",
    "recall = recall_score(testing_y, y_pred)\n",
    "print(recall)\n",
    "# Summary of the model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 632us/step\n",
      "0.6678321678321678\n"
     ]
    }
   ],
   "source": [
    "y_prednew = (model.predict(dfprecnew) > 0.5).astype(int)\n",
    "\n",
    "recall = recall_score(labelsnew, y_prednew)\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostClassifier(estimator=RandomForestClassifier(criterion=&#x27;entropy&#x27;,\n",
       "                                                    max_depth=10,\n",
       "                                                    min_samples_leaf=2),\n",
       "                   learning_rate=0.1, n_estimators=100)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier(estimator=RandomForestClassifier(criterion=&#x27;entropy&#x27;,\n",
       "                                                    max_depth=10,\n",
       "                                                    min_samples_leaf=2),\n",
       "                   learning_rate=0.1, n_estimators=100)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=10, min_samples_leaf=2)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=10, min_samples_leaf=2)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "AdaBoostClassifier(estimator=RandomForestClassifier(criterion='entropy',\n",
       "                                                    max_depth=10,\n",
       "                                                    min_samples_leaf=2),\n",
       "                   learning_rate=0.1, n_estimators=100)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada1 = AdaBoostClassifier(\n",
    "    estimator=RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        criterion='entropy',\n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=2,\n",
    "        max_features='sqrt',\n",
    "        bootstrap=True,\n",
    "    ),\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1\n",
    ")\n",
    "ada1.fit(training_x, training_y['Label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9195990180032734, Precision: 0.9289749798224375, Recall: 0.9138547042477173, F1-Score: 0.9213528116870122\n",
      "Confusion Matrix: \n",
      " [[2193  176]\n",
      " [ 217 2302]]\n"
     ]
    }
   ],
   "source": [
    "ada_pred1 = ada1.predict(testing_x)\n",
    "\n",
    "accuracy = accuracy_score(testing_y, ada_pred1)\n",
    "precision = precision_score(testing_y, ada_pred1)\n",
    "recall = recall_score(testing_y, ada_pred1)\n",
    "f1 = f1_score(testing_y, ada_pred1)\n",
    "conf = confusion_matrix(testing_y, ada_pred1)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1-Score: {f1}\")\n",
    "print(f\"Confusion Matrix: \\n {conf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6638655462184874, Precision: 0.6730769230769231, Recall: 0.8566433566433567, F1-Score: 0.7538461538461538\n",
      "Confusion Matrix: \n",
      " [[ 71 119]\n",
      " [ 41 245]]\n"
     ]
    }
   ],
   "source": [
    "ada_prednew1 = ada1.predict(dfprecnew)\n",
    "accuracy = accuracy_score(labelsnew, ada_prednew1)\n",
    "precision = precision_score(labelsnew, ada_prednew1)\n",
    "recall = recall_score(labelsnew, ada_prednew1)\n",
    "f1 = f1_score(labelsnew, ada_prednew1)\n",
    "conf = confusion_matrix(labelsnew, ada_prednew1)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1-Score: {f1}\")\n",
    "print(f\"Confusion Matrix: \\n {conf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing approach, instead of having a dataframe where equipment pieces are rows and the values are number \n",
    "### of fails to having a each column be a specific failed piece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = pattern_data.copy()\n",
    "encoded['Equipment'] = LabelEncoder().fit_transform(encoded['Equipment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = []\n",
    "for i in range(20):\n",
    "    column_names.append(f\"Failed Piece {i+1}\")\n",
    "newTactic = pd.DataFrame(columns = column_names)\n",
    "for column in newTactic:\n",
    "    newTactic[column] = [-1]*encoded.shape[0]\n",
    "newTacticLabel = [0]*encoded.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twindow = pd.Timedelta(days=3)\n",
    "\n",
    "for i in range(encoded.shape[0]):\n",
    "    temp = 0\n",
    "    for j in range(i, i+20):\n",
    "        if j>=encoded.shape[0]:\n",
    "            break\n",
    "        inner_eq = encoded.iloc[j]['Equipment']\n",
    "        newTactic[f\"Failed Piece {j-i+1}\"][i] = inner_eq\n",
    "        temp = j\n",
    "    cur_dt = encoded.iloc[temp]['FaultDateTime']\n",
    "    for j in range(temp, encoded.shape[0]):\n",
    "        inner_eq = pattern_data.iloc[j]['Equipment']\n",
    "        inner_dt = encoded.iloc[j]['FaultDateTime']\n",
    "        if inner_eq == 'ion source':\n",
    "            newTacticLabel[i] = 1\n",
    "            break\n",
    "        if (inner_dt - cur_dt) >= twindow:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_x, testing_x, training_y, testing_y = train_test_split(newTactic, newTacticLabel, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.661620294599018, Precision: 0.6768935762224353, Recall: 0.9022364217252397, F1-Score: 0.7734867159682279\n",
      "Confusion Matrix: \n",
      " [[ 410 1348]\n",
      " [ 306 2824]]\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    criterion='entropy',\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    bootstrap=True,\n",
    "\n",
    ")\n",
    "training_x.fillna(-1, inplace=True)\n",
    "testing_x.fillna(-1, inplace=True)\n",
    "\n",
    "rf.fit(training_x, training_y)\n",
    "rf_pred = rf.predict(testing_x)\n",
    "\n",
    "accuracy = accuracy_score(testing_y, rf_pred)\n",
    "precision = precision_score(testing_y, rf_pred, zero_division=1)\n",
    "recall = recall_score(testing_y, rf_pred, zero_division=1)\n",
    "f1 = f1_score(testing_y, rf_pred, zero_division=1)\n",
    "conf = confusion_matrix(testing_y, rf_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1-Score: {f1}\")\n",
    "print(f\"Confusion Matrix: \\n {conf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the zeros table to a time window instead of n components\n",
    "\n",
    "Change the second approach to include timestamps\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
